{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP16EFbmB0sblcjdBVaxQ/n"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "71bcb9bca1af44e6aa0d1b64672192f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_722f19bab1ca481ebae082078cab5354",
              "IPY_MODEL_8bc18a17eabd42f8a9c8853bc73644bd",
              "IPY_MODEL_704dc7894fe04db49c6a58b7cff35f15"
            ],
            "layout": "IPY_MODEL_2efe6da24310408a9ce9c9c88a46d580"
          }
        },
        "722f19bab1ca481ebae082078cab5354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4085e0b029a54dac9cdd44f3f8a2c9fd",
            "placeholder": "​",
            "style": "IPY_MODEL_bce6a3ea5db741a68f82dac74c39e75f",
            "value": "Tokenizing training dataset: 100%"
          }
        },
        "8bc18a17eabd42f8a9c8853bc73644bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f68d33b14ce443a8f5872161cc91840",
            "max": 7000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13abeba079344686b8b3cacda99f13cc",
            "value": 7000
          }
        },
        "704dc7894fe04db49c6a58b7cff35f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_590b790209ea48cfb3643021073eee58",
            "placeholder": "​",
            "style": "IPY_MODEL_7dfffc42418b49ce9059a2bd473b07d4",
            "value": " 7000/7000 [00:02&lt;00:00, 2959.69 examples/s]"
          }
        },
        "2efe6da24310408a9ce9c9c88a46d580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4085e0b029a54dac9cdd44f3f8a2c9fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce6a3ea5db741a68f82dac74c39e75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f68d33b14ce443a8f5872161cc91840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13abeba079344686b8b3cacda99f13cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "590b790209ea48cfb3643021073eee58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dfffc42418b49ce9059a2bd473b07d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3021554b16747f8975b2ec4252b7b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f01d74090d84fbd978114686110949b",
              "IPY_MODEL_3ac128602b204aa2bf3c0fa0248335be",
              "IPY_MODEL_6863918eca3d46a1971641657993e75a"
            ],
            "layout": "IPY_MODEL_03cde3f800034cbca2d221076818fbc0"
          }
        },
        "0f01d74090d84fbd978114686110949b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_495dac26421d4e8dbbdfe02307c745ea",
            "placeholder": "​",
            "style": "IPY_MODEL_b7901bf7e8e04f84b464581c9a963b3c",
            "value": "Tokenizing development dataset: 100%"
          }
        },
        "3ac128602b204aa2bf3c0fa0248335be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65a2ccc6f4c742dabae3350904a4ee1e",
            "max": 1034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9637294ed1e4f4aa398a976e1a00034",
            "value": 1034
          }
        },
        "6863918eca3d46a1971641657993e75a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fe8f7facc4a4e77a3a9de9294ed4f88",
            "placeholder": "​",
            "style": "IPY_MODEL_a71962a77cb14ab9b75c824b845daf0c",
            "value": " 1034/1034 [00:00&lt;00:00, 3236.07 examples/s]"
          }
        },
        "03cde3f800034cbca2d221076818fbc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "495dac26421d4e8dbbdfe02307c745ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7901bf7e8e04f84b464581c9a963b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65a2ccc6f4c742dabae3350904a4ee1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9637294ed1e4f4aa398a976e1a00034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9fe8f7facc4a4e77a3a9de9294ed4f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a71962a77cb14ab9b75c824b845daf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8muKPChjTH2x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "71bcb9bca1af44e6aa0d1b64672192f4",
            "722f19bab1ca481ebae082078cab5354",
            "8bc18a17eabd42f8a9c8853bc73644bd",
            "704dc7894fe04db49c6a58b7cff35f15",
            "2efe6da24310408a9ce9c9c88a46d580",
            "4085e0b029a54dac9cdd44f3f8a2c9fd",
            "bce6a3ea5db741a68f82dac74c39e75f",
            "2f68d33b14ce443a8f5872161cc91840",
            "13abeba079344686b8b3cacda99f13cc",
            "590b790209ea48cfb3643021073eee58",
            "7dfffc42418b49ce9059a2bd473b07d4",
            "a3021554b16747f8975b2ec4252b7b65",
            "0f01d74090d84fbd978114686110949b",
            "3ac128602b204aa2bf3c0fa0248335be",
            "6863918eca3d46a1971641657993e75a",
            "03cde3f800034cbca2d221076818fbc0",
            "495dac26421d4e8dbbdfe02307c745ea",
            "b7901bf7e8e04f84b464581c9a963b3c",
            "65a2ccc6f4c742dabae3350904a4ee1e",
            "b9637294ed1e4f4aa398a976e1a00034",
            "9fe8f7facc4a4e77a3a9de9294ed4f88",
            "a71962a77cb14ab9b75c824b845daf0c"
          ]
        },
        "outputId": "42ba4302-7bef-4ddf-d166-ab394743bff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "CUDA available: True\n",
            "GPU device: NVIDIA A100-SXM4-40GB\n",
            "Memory: 42.47 GB\n",
            "Sun Apr  6 13:09:16 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0             54W /  400W |    5119MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Installing required packages...\n",
            "Packages installed.\n",
            "\n",
            "Verifying package versions...\n",
            "Name: datasets\n",
            "Version: 3.5.0\n",
            "Summary: HuggingFace community-driven open-source library of datasets\n",
            "Home-page: https://github.com/huggingface/datasets\n",
            "Author: HuggingFace Inc.\n",
            "Author-email: thomas@huggingface.co\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: aiohttp, dill, filelock, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, pyarrow, pyyaml, requests, tqdm, xxhash\n",
            "Required-by: evaluate\n",
            "---\n",
            "Name: transformers\n",
            "Version: 4.50.3\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: peft, sentence-transformers\n",
            "---\n",
            "Name: evaluate\n",
            "Version: 0.4.3\n",
            "Summary: HuggingFace community-driven open-source library of evaluation\n",
            "Home-page: https://github.com/huggingface/evaluate\n",
            "Author: HuggingFace Inc.\n",
            "Author-email: leandro@huggingface.co\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: datasets, dill, fsspec, huggingface-hub, multiprocess, numpy, packaging, pandas, requests, tqdm, xxhash\n",
            "Required-by: \n",
            "---\n",
            "Name: tensorboard\n",
            "Version: 2.18.0\n",
            "Summary: TensorBoard lets you watch Tensors Flow\n",
            "Home-page: https://github.com/tensorflow/tensorboard\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: absl-py, grpcio, markdown, numpy, packaging, protobuf, setuptools, six, tensorboard-data-server, werkzeug\n",
            "Required-by: tensorflow\n",
            "---\n",
            "Name: accelerate\n",
            "Version: 1.5.2\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: zach.mueller@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: peft\n",
            "---\n",
            "Name: huggingface-hub\n",
            "Version: 0.30.1\n",
            "Summary: Client library to download and publish models, datasets and other repos on the huggingface.co hub\n",
            "Home-page: https://github.com/huggingface/huggingface_hub\n",
            "Author: Hugging Face, Inc.\n",
            "Author-email: julien@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, fsspec, packaging, pyyaml, requests, tqdm, typing-extensions\n",
            "Required-by: accelerate, datasets, diffusers, evaluate, peft, sentence-transformers, timm, tokenizers, transformers\n",
            "---\n",
            "Name: torch\n",
            "Version: 2.6.0+cu124\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchvision\n",
            "---\n",
            "Name: pandas\n",
            "Version: 2.2.2\n",
            "Summary: Powerful data structures for data analysis, time series, and statistics\n",
            "Home-page: https://pandas.pydata.org\n",
            "Author: \n",
            "Author-email: The Pandas Development Team <pandas-dev@python.org>\n",
            "License: BSD 3-Clause License\n",
            "\n",
            "Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n",
            "All rights reserved.\n",
            "\n",
            "Copyright (c) 2011-2023, Open source contributors.\n",
            "\n",
            "Redistribution and use in source and binary forms, with or without\n",
            "modification, are permitted provided that the following conditions are met:\n",
            "\n",
            "* Redistributions of source code must retain the above copyright notice, this\n",
            "  list of conditions and the following disclaimer.\n",
            "\n",
            "* Redistributions in binary form must reproduce the above copyright notice,\n",
            "  this list of conditions and the following disclaimer in the documentation\n",
            "  and/or other materials provided with the distribution.\n",
            "\n",
            "* Neither the name of the copyright holder nor the names of its\n",
            "  contributors may be used to endorse or promote products derived from\n",
            "  this software without specific prior written permission.\n",
            "\n",
            "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
            "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
            "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
            "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
            "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
            "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
            "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
            "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
            "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
            "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: numpy, python-dateutil, pytz, tzdata\n",
            "Required-by: arviz, bigframes, bigquery-magics, bokeh, bqplot, cmdstanpy, cudf-cu12, cufflinks, dask-cuda, dask-cudf-cu12, dask-expr, datascience, datasets, db-dtypes, dopamine_rl, evaluate, fastai, geemap, geopandas, google-colab, gspread-dataframe, holoviews, mizani, mlxtend, pandas-datareader, pandas-gbq, panel, plotnine, prophet, pymc, seaborn, shap, sklearn-pandas, statsmodels, vega-datasets, xarray, yfinance\n",
            "------------------------------\n",
            "--- Running Experiment: t5_large_sql_types_schema_v5 ---\n",
            "Model: t5-large\n",
            "Schema Format: sql (with Types)\n",
            "Epochs: 25\n",
            "Learning Rate: 1e-05\n",
            "Per Device Batch Size: 2\n",
            "Gradient Accumulation Steps: 8\n",
            "Effective Batch Size: 16\n",
            "Weight Decay: 0.01\n",
            "Gradient Clipping: 1.0\n",
            "Max Input Length: 1024\n",
            "Max Target Length: 256\n",
            "Warmup Ratio: 0.1\n",
            "FP16 Enabled: False\n",
            "\n",
            "--- Setting up Dataset ---\n",
            "Copying dataset from Google Drive path: /content/drive/MyDrive/text2sql/datasets/spider\n",
            "Copying dataset files to local Colab storage...\n",
            "'/content/drive/MyDrive/text2sql/datasets/spider/tables.json' -> '/content/datasets/spider/tables.json'\n",
            "'/content/drive/MyDrive/text2sql/datasets/spider/train_spider.json' -> '/content/datasets/spider/train_spider.json'\n",
            "'/content/drive/MyDrive/text2sql/datasets/spider/dev.json' -> '/content/datasets/spider/dev.json'\n",
            "Dataset files copied successfully.\n",
            "\n",
            "Loading database schemas...\n",
            "Loading tables.json from: /content/datasets/spider/tables.json\n",
            "Loaded schemas for 166 databases.\n",
            "Loading datasets...\n",
            "Loading data from: /content/datasets/spider/train_spider.json\n",
            "Enhancing 7000 prompts...\n",
            "  Processed 700/7000 examples...\n",
            "  Processed 1400/7000 examples...\n",
            "  Processed 2100/7000 examples...\n",
            "  Processed 2800/7000 examples...\n",
            "  Processed 3500/7000 examples...\n",
            "  Processed 4200/7000 examples...\n",
            "  Processed 4900/7000 examples...\n",
            "  Processed 5600/7000 examples...\n",
            "  Processed 6300/7000 examples...\n",
            "  Processed 7000/7000 examples...\n",
            "Prepared 7000 examples from /content/datasets/spider/train_spider.json.\n",
            "Loading data from: /content/datasets/spider/dev.json\n",
            "Enhancing 1034 prompts...\n",
            "  Processed 103/1034 examples...\n",
            "  Processed 206/1034 examples...\n",
            "  Processed 309/1034 examples...\n",
            "  Processed 412/1034 examples...\n",
            "  Processed 515/1034 examples...\n",
            "  Processed 618/1034 examples...\n",
            "  Processed 721/1034 examples...\n",
            "  Processed 824/1034 examples...\n",
            "  Processed 927/1034 examples...\n",
            "  Processed 1030/1034 examples...\n",
            "  Processed 1034/1034 examples...\n",
            "Prepared 1034 examples from /content/datasets/spider/dev.json.\n",
            "\n",
            "Sample Prompts (with types):\n",
            "\n",
            "--- Example 1 ---\n",
            "Input length: 571 characters\n",
            "Input: translate English to SQL: How many heads of the departments are older than 56 ? | database: department_management | schema:\\nTable: department\\nColumns: Budget_in_Billions (NUMBER), Creation (TEXT), Department_ID (NUMBER) (PRIMARY KEY), Name (TEXT), Num_Employees (NUMBER), Ranking (NUMBER)\\nTable: head\\nColumns: age (NUMBER), born_state (TEXT), head_ID (NUMBER) (PRIMARY KEY), name (TEXT)\\nTable: management\\nColumns: department_ID (NUMBER) (PRIMARY KEY) (FOREIGN KEY -> department.Department_ID), head_ID (NUMBER) (FOREIGN KEY -> head.head_ID), temporary_acting (TEXT)...\n",
            "Output: SELECT count(*) FROM head WHERE age  >  56\n",
            "\n",
            "--- Example 2 ---\n",
            "Input length: 595 characters\n",
            "Input: translate English to SQL: List the name, born state and age of the heads of departments ordered by age. | database: department_management | schema:\\nTable: department\\nColumns: Budget_in_Billions (NUMBER), Creation (TEXT), Department_ID (NUMBER) (PRIMARY KEY), Name (TEXT), Num_Employees (NUMBER), Ranking (NUMBER)\\nTable: head\\nColumns: age (NUMBER), born_state (TEXT), head_ID (NUMBER) (PRIMARY KEY), name (TEXT)\\nTable: management\\nColumns: department_ID (NUMBER) (PRIMARY KEY) (FOREIGN KEY -> department.Department_ID), head_ID (NUMBER) (FOREIGN KEY -> head.head_ID), temporary_acting (TEXT)...\n",
            "Output: SELECT name ,  born_state ,  age FROM head ORDER BY age\n",
            "\n",
            "Loading model: t5-large...\n",
            "Model and tokenizer loaded.\n",
            "\n",
            "Tokenizing datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing training dataset:   0%|          | 0/7000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71bcb9bca1af44e6aa0d1b64672192f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3980: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing development dataset:   0%|          | 0/1034 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3021554b16747f8975b2ec4252b7b65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset tokenized: 7000 examples\n",
            "Development dataset tokenized: 1034 examples\n",
            "\n",
            "Data collator initializing...\n",
            "Data collator using label_pad_token_id: -100\n",
            "\n",
            "Configuring training arguments...\n",
            "Total training steps: 10925, Warmup steps: 1092\n",
            "\n",
            "Initializing Trainer...\n",
            "Trainer initialized.\n",
            "\n",
            "--- Starting Training ---\n",
            "Running initial evaluation to check for NaN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-2-fae58eb1dfb0>:346: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='518' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 23:46]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-11:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 244, in run\n",
            "    self._run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 289, in _run\n",
            "    self._record_writer.flush()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/summary/writer/record_writer.py\", line 43, in flush\n",
            "    self._writer.flush()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/lib/io/file_io.py\", line 221, in flush\n",
            "    self._writable_file.flush()\n",
            "tensorflow.python.framework.errors_impl.FailedPreconditionError: /content/drive/MyDrive/text2sql/logs/t5_large_sql_types_schema_v4/events.out.tfevents.1743944854.71614af774ea.5565.0; Transport endpoint is not connected\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial evaluation result: {'eval_loss': 3.3948590755462646, 'eval_model_preparation_time': 1.1534, 'eval_runtime': 21.6196, 'eval_samples_per_second': 47.827, 'eval_steps_per_second': 11.98}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10925' max='10925' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10925/10925 9:29:48, Epoch 24/25]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Model Preparation Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.402400</td>\n",
              "      <td>2.987877</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.504100</td>\n",
              "      <td>1.912930</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.423800</td>\n",
              "      <td>1.078967</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.072200</td>\n",
              "      <td>0.822407</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.876900</td>\n",
              "      <td>0.721675</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.769300</td>\n",
              "      <td>0.660260</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.713900</td>\n",
              "      <td>0.617687</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.666800</td>\n",
              "      <td>0.589750</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.642400</td>\n",
              "      <td>0.569253</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.596400</td>\n",
              "      <td>0.555962</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.578000</td>\n",
              "      <td>0.545147</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.560200</td>\n",
              "      <td>0.536557</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.548300</td>\n",
              "      <td>0.530343</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.543300</td>\n",
              "      <td>0.525184</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.538700</td>\n",
              "      <td>0.521118</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.535700</td>\n",
              "      <td>0.518139</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.524900</td>\n",
              "      <td>0.515620</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.530700</td>\n",
              "      <td>0.512643</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.527500</td>\n",
              "      <td>0.511860</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.534400</td>\n",
              "      <td>0.511057</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.525400</td>\n",
              "      <td>0.510368</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.518600</td>\n",
              "      <td>0.510252</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.520400</td>\n",
              "      <td>0.510048</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.516400</td>\n",
              "      <td>0.509907</td>\n",
              "      <td>1.153400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Finished ---\n",
            "***** train metrics *****\n",
            "  epoch                    =      24.944\n",
            "  total_flos               = 444282020GF\n",
            "  train_loss               =        0.86\n",
            "  train_runtime            =  9:29:51.99\n",
            "  train_samples_per_second =       5.118\n",
            "  train_steps_per_second   =        0.32\n",
            "\n",
            "Saving the final model...\n",
            "Model saved to /content/drive/MyDrive/text2sql/t5_large_sql_types_schema_v5\n",
            "Training summary saved to /content/drive/MyDrive/text2sql/t5_large_sql_types_schema_v5/training_summary.txt\n",
            "Training completed in 9h 30m 18s\n",
            "\\n--- Script Finished ---\n"
          ]
        }
      ],
      "source": [
        "# T5 Text-to-SQL Fine-Tuning Script Optimized for Google Colab\n",
        "# For bachelor thesis on schema-enhanced Text-to-SQL generation\n",
        "# VERSION: Disabled fp16 to debug NaN loss\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU device: {gpu_name}\")\n",
        "    print(f\"Memory: {gpu_memory:.2f} GB\")\n",
        "    if 'A100' not in gpu_name and 'H100' not in gpu_name: # Basic check\n",
        "         print(\"Warning: T5-Large is memory intensive. Ensure sufficient GPU RAM.\")\n",
        "\n",
        "# Show GPU info\n",
        "!nvidia-smi\n",
        "\n",
        "# Install required packages\n",
        "print(\"Installing required packages...\")\n",
        "!pip install -q datasets transformers evaluate tensorboard accelerate huggingface-hub pandas\n",
        "print(\"Packages installed.\")\n",
        "\n",
        "# --- Verify Installation (Optional) ---\n",
        "print(\"\\nVerifying package versions...\")\n",
        "!pip show datasets transformers evaluate tensorboard accelerate huggingface-hub torch pandas\n",
        "print(\"-\" * 30)\n",
        "\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "from typing import Dict, List, Any\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    set_seed\n",
        ")\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed(42)\n",
        "\n",
        "# --- Configuration ---\n",
        "EXPERIMENT_NAME = \"t5_large_sql_types_schema_v5\"\n",
        "SCHEMA_FORMAT = \"sql\"\n",
        "MODEL_SIZE = \"large\"\n",
        "EPOCHS = 25\n",
        "LEARNING_RATE = 1e-5\n",
        "BATCH_SIZE = 2\n",
        "GRADIENT_ACCUMULATION_STEPS = 8\n",
        "WEIGHT_DECAY = 0.01\n",
        "MAX_INPUT_LENGTH = 1024\n",
        "MAX_TARGET_LENGTH = 256\n",
        "WARMUP_RATIO = 0.1\n",
        "MAX_GRAD_NORM = 1.0\n",
        "RESUME_FROM_CHECKPOINT = False\n",
        "\n",
        "# Google Drive paths\n",
        "DRIVE_BASE_DIR = \"/content/drive/MyDrive/text2sql\"\n",
        "DRIVE_OUTPUT_DIR = f\"{DRIVE_BASE_DIR}/{EXPERIMENT_NAME}\"\n",
        "DRIVE_DATASET_SOURCE_DIR = f\"{DRIVE_BASE_DIR}/datasets/spider\"\n",
        "DRIVE_LOGS_DIR = f\"{DRIVE_BASE_DIR}/logs/{EXPERIMENT_NAME}\"\n",
        "\n",
        "# Local paths\n",
        "LOCAL_DATASET_DIR = \"/content/datasets/spider\"\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(DRIVE_BASE_DIR, exist_ok=True)\n",
        "os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(DRIVE_LOGS_DIR, exist_ok=True)\n",
        "os.makedirs(LOCAL_DATASET_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"--- Running Experiment: {EXPERIMENT_NAME} ---\")\n",
        "print(f\"Model: t5-{MODEL_SIZE}\")\n",
        "print(f\"Schema Format: {SCHEMA_FORMAT} (with Types)\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Per Device Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Gradient Accumulation Steps: {GRADIENT_ACCUMULATION_STEPS}\")\n",
        "print(f\"Effective Batch Size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
        "print(f\"Weight Decay: {WEIGHT_DECAY}\")\n",
        "print(f\"Gradient Clipping: {MAX_GRAD_NORM}\")\n",
        "print(f\"Max Input Length: {MAX_INPUT_LENGTH}\")\n",
        "print(f\"Max Target Length: {MAX_TARGET_LENGTH}\")\n",
        "print(f\"Warmup Ratio: {WARMUP_RATIO}\")\n",
        "print(f\"FP16 Enabled: False\")\n",
        "\n",
        "# --- Schema Utilities ---\n",
        "def load_tables_json(tables_path):\n",
        "    \"\"\"Load the tables.json file containing schema information.\"\"\"\n",
        "    full_path = os.path.join(LOCAL_DATASET_DIR, tables_path)\n",
        "    print(f\"Loading tables.json from: {full_path}\")\n",
        "    try:\n",
        "        with open(full_path, 'r', encoding='utf-8') as f:\n",
        "            tables_data = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: tables.json not found at {full_path}\")\n",
        "        raise\n",
        "    db_schemas = {db_info['db_id']: db_info for db_info in tables_data}\n",
        "    return db_schemas\n",
        "\n",
        "def get_sql_schema_string(db_id, db_schemas):\n",
        "    \"\"\"Create SQL schema string including types, PKs, FKs.\"\"\"\n",
        "    if db_id not in db_schemas: raise ValueError(f\"DB ID '{db_id}' not found\")\n",
        "    schema_info = db_schemas[db_id]\n",
        "    tables = schema_info['table_names_original']\n",
        "    columns = schema_info['column_names_original']\n",
        "    column_types = schema_info['column_types']\n",
        "    primary_keys = set(schema_info.get('primary_keys', []))\n",
        "    fk_dict = {}\n",
        "    if isinstance(schema_info.get('foreign_keys'), list):\n",
        "        for fk_pair in schema_info['foreign_keys']:\n",
        "             if isinstance(fk_pair, (list, tuple)) and len(fk_pair) == 2:\n",
        "                 col1_idx, col2_idx = fk_pair\n",
        "                 if isinstance(col1_idx, int) and isinstance(col2_idx, int): fk_dict[col1_idx] = col2_idx\n",
        "    table_defs = []\n",
        "    for i, table in enumerate(tables):\n",
        "        table_columns = []\n",
        "        for col_idx, (tab_idx, col_name) in enumerate(columns):\n",
        "            if tab_idx == i:\n",
        "                col_type = column_types[col_idx].upper()\n",
        "                col_info = f\"{col_name} ({col_type})\"\n",
        "                if col_idx in primary_keys: col_info += \" (PRIMARY KEY)\"\n",
        "                if col_idx in fk_dict:\n",
        "                    ref_col_idx = fk_dict[col_idx]\n",
        "                    if 0 <= ref_col_idx < len(columns):\n",
        "                         ref_tab_idx, ref_col_name = columns[ref_col_idx]\n",
        "                         if 0 <= ref_tab_idx < len(tables):\n",
        "                              ref_table = tables[ref_tab_idx]\n",
        "                              col_info += f\" (FOREIGN KEY -> {ref_table}.{ref_col_name})\"\n",
        "                table_columns.append(col_info)\n",
        "        if table_columns:\n",
        "            table_columns.sort()\n",
        "            table_def = f\"Table: {table}\\\\nColumns: {', '.join(table_columns)}\"\n",
        "            table_defs.append(table_def)\n",
        "    table_defs.sort()\n",
        "    return \"\\\\n\".join(table_defs)\n",
        "\n",
        "def get_compact_schema_string(db_id, db_schemas):\n",
        "    \"\"\"Create compact schema string.\"\"\"\n",
        "    if db_id not in db_schemas: raise ValueError(f\"DB ID '{db_id}' not found\")\n",
        "    schema_info = db_schemas[db_id]\n",
        "    tables = schema_info['table_names_original']\n",
        "    columns = schema_info['column_names_original']\n",
        "    table_columns = {}\n",
        "    for i, table in enumerate(tables):\n",
        "        cols = []\n",
        "        for tab_idx, col_name in columns:\n",
        "            if tab_idx == i: cols.append(col_name)\n",
        "        if cols:\n",
        "             cols.sort()\n",
        "             table_columns[table] = cols\n",
        "    parts = []\n",
        "    for table in sorted(table_columns.keys()):\n",
        "        cols = table_columns[table]\n",
        "        part = f\"{table}({', '.join(cols)})\"\n",
        "        parts.append(part)\n",
        "    return \" \".join(parts)\n",
        "\n",
        "def enhance_prompts_with_schema(data_df, db_schemas, schema_format=\"sql\"):\n",
        "    \"\"\"Enhance input prompts with schema information.\"\"\"\n",
        "    enhanced_rows = []\n",
        "    skipped_count = 0\n",
        "    total_count = len(data_df)\n",
        "    print_interval = max(1, total_count // 10)\n",
        "    print(f\"Enhancing {total_count} prompts...\")\n",
        "    for index, example in data_df.iterrows():\n",
        "        if index > 0 and index % print_interval == 0: print(f\"  Processed {index}/{total_count} examples...\")\n",
        "        db_id = example['db_id']\n",
        "        try:\n",
        "            if schema_format == \"compact\":\n",
        "                schema_str = get_compact_schema_string(db_id, db_schemas)\n",
        "                input_text = f\"translate English to SQL: {example['question']} | database: {db_id} | schema: {schema_str}\"\n",
        "            elif schema_format == \"sql\":\n",
        "                schema_str = get_sql_schema_string(db_id, db_schemas)\n",
        "                input_text = f\"translate English to SQL: {example['question']} | database: {db_id} | schema:\\\\n{schema_str}\"\n",
        "            elif schema_format == \"both\":\n",
        "                compact_str = get_compact_schema_string(db_id, db_schemas)\n",
        "                sql_str = get_sql_schema_string(db_id, db_schemas)\n",
        "                input_text = f\"translate English to SQL: {example['question']} | database: {db_id} | schema: {compact_str}\\\\nDetailed schema:\\\\n{sql_str}\"\n",
        "            else: input_text = f\"translate English to SQL: {example['question']} | database: {db_id}\"\n",
        "            output_text = example['query']\n",
        "            enhanced_rows.append({\"input_text\": input_text, \"output_text\": output_text})\n",
        "        except Exception as e:\n",
        "             print(f\"Warning: Skipping example for db_id '{db_id}': {e}\")\n",
        "             skipped_count += 1\n",
        "    print(f\"  Processed {total_count}/{total_count} examples...\")\n",
        "    if skipped_count > 0: print(f\"Skipped {skipped_count} examples.\")\n",
        "    if not enhanced_rows: print(\"Warning: No rows enhanced.\")\n",
        "    return pd.DataFrame(enhanced_rows)\n",
        "\n",
        "# --- Setup Local Dataset from Drive ---\n",
        "def setup_local_dataset_from_drive():\n",
        "    \"\"\"Copy the Spider dataset JSON files from Google Drive to local storage.\"\"\"\n",
        "    print(f\"\\n--- Setting up Dataset ---\")\n",
        "    print(f\"Copying dataset from Google Drive path: {DRIVE_DATASET_SOURCE_DIR}\")\n",
        "    drive_tables_path = f\"{DRIVE_DATASET_SOURCE_DIR}/tables.json\"\n",
        "    drive_train_path = f\"{DRIVE_DATASET_SOURCE_DIR}/train_spider.json\"\n",
        "    drive_dev_path = f\"{DRIVE_DATASET_SOURCE_DIR}/dev.json\"\n",
        "    all_paths_exist = all(os.path.exists(p) for p in [drive_tables_path, drive_train_path, drive_dev_path])\n",
        "    if all_paths_exist:\n",
        "        print(\"Copying dataset files to local Colab storage...\")\n",
        "        try:\n",
        "            !cp -v \"{drive_tables_path}\" \"{LOCAL_DATASET_DIR}/\"\n",
        "            !cp -v \"{drive_train_path}\" \"{LOCAL_DATASET_DIR}/\"\n",
        "            !cp -v \"{drive_dev_path}\" \"{LOCAL_DATASET_DIR}/\"\n",
        "            print(\"Dataset files copied successfully.\")\n",
        "        except Exception as e:\n",
        "             print(f\"Error during file copy: {e}\")\n",
        "             raise\n",
        "    else:\n",
        "        missing = [p for p in [drive_tables_path, drive_train_path, drive_dev_path] if not os.path.exists(p)]\n",
        "        raise FileNotFoundError(f\"Missing files in Drive: {missing}\")\n",
        "\n",
        "# --- Run Setup Function ---\n",
        "setup_local_dataset_from_drive()\n",
        "\n",
        "# --- Load Database Schemas ---\n",
        "print(\"\\nLoading database schemas...\")\n",
        "db_schemas = load_tables_json('tables.json')\n",
        "print(f\"Loaded schemas for {len(db_schemas)} databases.\")\n",
        "\n",
        "# --- Load and Prepare Datasets ---\n",
        "def load_and_prepare_data(file_path, db_schemas_dict, schema_fmt):\n",
        "    \"\"\"Load, enhance and prepare dataset.\"\"\"\n",
        "    actual_file_path = os.path.join(LOCAL_DATASET_DIR, file_path)\n",
        "    print(f\"Loading data from: {actual_file_path}\")\n",
        "    try:\n",
        "        with open(actual_file_path, 'r', encoding='utf-8') as f:\n",
        "            spider_data = json.load(f)\n",
        "        df = pd.DataFrame(spider_data)\n",
        "        t5_data_df = enhance_prompts_with_schema(df, db_schemas_dict, schema_format=schema_fmt)\n",
        "        if t5_data_df is None or t5_data_df.empty: return None\n",
        "        dataset = Dataset.from_pandas(t5_data_df)\n",
        "        print(f\"Prepared {len(dataset)} examples from {actual_file_path}.\")\n",
        "        return dataset\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing data from {actual_file_path}: {e}\")\n",
        "        raise\n",
        "print(\"Loading datasets...\")\n",
        "train_dataset = load_and_prepare_data('train_spider.json', db_schemas, SCHEMA_FORMAT)\n",
        "dev_dataset = load_and_prepare_data('dev.json', db_schemas, SCHEMA_FORMAT)\n",
        "if train_dataset is None or dev_dataset is None:\n",
        "     raise ValueError(\"Failed to load train or dev dataset.\")\n",
        "\n",
        "# Log some examples to verify prompts\n",
        "print(\"\\nSample Prompts (with types):\")\n",
        "for i in range(min(2, len(train_dataset))):\n",
        "    print(f\"\\n--- Example {i+1} ---\")\n",
        "    print(f\"Input length: {len(train_dataset[i]['input_text'])} characters\")\n",
        "    print(f\"Input: {train_dataset[i]['input_text'][:600]}...\") # Show more\n",
        "    print(f\"Output: {train_dataset[i]['output_text']}\")\n",
        "\n",
        "# --- Load Model and Tokenizer ---\n",
        "model_name = f\"t5-{MODEL_SIZE}\"\n",
        "print(f\"\\nLoading model: {model_name}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_name,\n",
        "    return_dict=True\n",
        ")\n",
        "print(\"Model and tokenizer loaded.\")\n",
        "\n",
        "# --- Tokenization Function ---\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenizes input and target text.\"\"\"\n",
        "    input_texts = [text if text is not None else \"\" for text in examples['input_text']]\n",
        "    output_texts = [text if text is not None else \"\" for text in examples['output_text']]\n",
        "    model_inputs = tokenizer(\n",
        "        input_texts, max_length=MAX_INPUT_LENGTH, truncation=True,\n",
        "    )\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            output_texts, max_length=MAX_TARGET_LENGTH, truncation=True,\n",
        "        )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# --- Tokenize the Datasets ---\n",
        "print(\"\\nTokenizing datasets...\")\n",
        "tokenized_train = train_dataset.map(\n",
        "    tokenize_function, batched=True, remove_columns=train_dataset.column_names, desc=\"Tokenizing training dataset\"\n",
        ")\n",
        "tokenized_dev = dev_dataset.map(\n",
        "    tokenize_function, batched=True, remove_columns=dev_dataset.column_names, desc=\"Tokenizing development dataset\"\n",
        ")\n",
        "print(f\"Training dataset tokenized: {len(tokenized_train)} examples\")\n",
        "print(f\"Development dataset tokenized: {len(tokenized_dev)} examples\")\n",
        "\n",
        "# --- Data Collator ---\n",
        "print(\"\\nData collator initializing...\")\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=-100,\n",
        "    padding=\"longest\",\n",
        "    pad_to_multiple_of=None\n",
        ")\n",
        "print(f\"Data collator using label_pad_token_id: {data_collator.label_pad_token_id}\")\n",
        "\n",
        "# --- Training Arguments ---\n",
        "print(\"\\nConfiguring training arguments...\")\n",
        "total_steps = len(tokenized_train) // (BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS) * EPOCHS\n",
        "warmup_steps = int(total_steps * WARMUP_RATIO)\n",
        "print(f\"Total training steps: {total_steps}, Warmup steps: {warmup_steps}\")\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=DRIVE_OUTPUT_DIR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
        "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    warmup_steps=warmup_steps,\n",
        "    bf16=True,\n",
        "    bf16_full_eval=True,\n",
        "    fp16=False,\n",
        "    gradient_checkpointing=True,\n",
        "    max_grad_norm=MAX_GRAD_NORM,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    logging_dir=DRIVE_LOGS_DIR,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    report_to=\"tensorboard\",\n",
        "    optim=\"adafactor\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# --- Trainer Initialization ---\n",
        "print(\"\\nInitializing Trainer...\")\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_dev,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "print(\"Trainer initialized.\")\n",
        "\n",
        "# --- Main Training Execution ---\n",
        "print(f\"\\n--- Starting Training ---\")\n",
        "start_time = time.time()\n",
        "checkpoint = None\n",
        "if RESUME_FROM_CHECKPOINT:\n",
        "    if os.path.isdir(DRIVE_OUTPUT_DIR):\n",
        "        checkpoints = [os.path.join(DRIVE_OUTPUT_DIR, d) for d in os.listdir(DRIVE_OUTPUT_DIR) if d.startswith('checkpoint-') and os.path.isdir(os.path.join(DRIVE_OUTPUT_DIR, d))]\n",
        "        if checkpoints:\n",
        "            latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('-')[-1]))\n",
        "            print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n",
        "            checkpoint = latest_checkpoint\n",
        "        else: print(f\"No checkpoint found in {DRIVE_OUTPUT_DIR}.\")\n",
        "    else: print(f\"Output directory {DRIVE_OUTPUT_DIR} does not exist.\")\n",
        "\n",
        "try:\n",
        "    print(\"Running initial evaluation to check for NaN...\")\n",
        "    initial_eval = trainer.evaluate()\n",
        "    print(f\"Initial evaluation result: {initial_eval}\")\n",
        "    if 'eval_loss' in initial_eval and np.isnan(initial_eval['eval_loss']):\n",
        "        print(\"ERROR: NaN detected in evaluation loss even with fp16=False. Check data or learning rate.\")\n",
        "        print(\"Proceeding with training despite initial NaN...\")\n",
        "\n",
        "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
        "\n",
        "    # --- Post-Training Actions ---\n",
        "    print(\"\\n--- Training Finished ---\")\n",
        "    metrics = train_result.metrics\n",
        "    trainer.log_metrics(\"train\", metrics)\n",
        "    trainer.save_metrics(\"train\", metrics)\n",
        "\n",
        "    print(\"\\nSaving the final model...\")\n",
        "    trainer.save_model()\n",
        "    trainer.save_state()\n",
        "    tokenizer.save_pretrained(training_args.output_dir)\n",
        "    print(f\"Model saved to {training_args.output_dir}\")\n",
        "\n",
        "    # Generate training report\n",
        "    elapsed_time = time.time() - start_time\n",
        "    hours, remainder = divmod(elapsed_time, 3600)\n",
        "    minutes, seconds = divmod(remainder, 60)\n",
        "    report_path = os.path.join(training_args.output_dir, \"training_summary.txt\")\n",
        "    with open(report_path, \"w\") as f:\n",
        "        f.write(f\"Experiment: {EXPERIMENT_NAME}\\\\n\")\n",
        "        f.write(f\"Model: t5-{MODEL_SIZE}\\\\n\")\n",
        "        f.write(f\"Schema Format: {SCHEMA_FORMAT} (with Types)\\\\n\")\n",
        "        f.write(f\"FP16 Enabled: {training_args.fp16}\\\\n\")\n",
        "        f.write(f\"Epochs Configured: {EPOCHS}\\\\n\")\n",
        "        f.write(f\"Epochs Trained: {metrics.get('epoch', 0.0):.2f}\\\\n\")\n",
        "        f.write(f\"Training Time: {int(hours)}h {int(minutes)}m {int(seconds)}s\\\\n\")\n",
        "        f.write(f\"Learning Rate: {LEARNING_RATE}\\\\n\")\n",
        "        f.write(f\"Batch Size (per device): {BATCH_SIZE}\\\\n\")\n",
        "        f.write(f\"Gradient Accumulation Steps: {GRADIENT_ACCUMULATION_STEPS}\\\\n\")\n",
        "        f.write(f\"Effective Batch Size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\\\\n\")\n",
        "        f.write(f\"Weight Decay: {WEIGHT_DECAY}\\\\n\")\n",
        "        f.write(f\"Warmup Ratio: {WARMUP_RATIO} (Steps: {warmup_steps})\\\\n\")\n",
        "        f.write(f\"Max Grad Norm: {MAX_GRAD_NORM}\\\\n\")\n",
        "        f.write(f\"Max Input Length: {MAX_INPUT_LENGTH}\\\\n\")\n",
        "        f.write(f\"Max Target Length: {MAX_TARGET_LENGTH}\\\\n\")\n",
        "        f.write(\"\\\\nTraining Metrics:\\\\n\")\n",
        "        for key, value in metrics.items():\n",
        "            f.write(f\"  {key}: {value}\\\\n\")\n",
        "        f.write(f\"\\\\nModel saved to: {training_args.output_dir}\\\\n\")\n",
        "        f.write(f\"To evaluate the model, use the evaluation script.\\\\n\")\n",
        "    print(f\"Training summary saved to {report_path}\")\n",
        "    print(f\"Training completed in {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\\\nTraining interrupted by user. Saving current state...\")\n",
        "    interrupted_path = os.path.join(training_args.output_dir, \"interrupted_checkpoint\")\n",
        "    if 'trainer' in locals() and hasattr(trainer, 'save_model'): trainer.save_model(interrupted_path)\n",
        "    if 'tokenizer' in locals() and hasattr(tokenizer, 'save_pretrained'): tokenizer.save_pretrained(interrupted_path)\n",
        "    print(f\"Interrupted checkpoint potentially saved to {interrupted_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\\\n--- An error occurred during training: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n",
        "\n",
        "print(\"\\\\n--- Script Finished ---\")\n"
      ]
    }
  ]
}