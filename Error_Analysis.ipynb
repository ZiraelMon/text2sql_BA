{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHRkBHGS1xcwJXMlUoxs79"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5ACoe4MY2yR"
      },
      "outputs": [],
      "source": [
        "# Text-to-SQL Error Analysis Script for Google Colab\n",
        "# For bachelor thesis on schema-enhanced Text-to-SQL generation\n",
        "\n",
        "# First, mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages (if needed)\n",
        "!pip install -q matplotlib seaborn pandas tqdm\n",
        "\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from typing import Dict, List, Any, Counter\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Configuration ---\n",
        "DRIVE_BASE_DIR = \"/content/drive/MyDrive/text2sql\"\n",
        "TARGET_EXPERIMENT_NAME = \"t5_large_sql_types_schema_v3_nofp16\"\n",
        "EVAL_OUTPUT_DIR = f\"{DRIVE_BASE_DIR}/eval_results/{TARGET_EXPERIMENT_NAME}\"\n",
        "PREDICTIONS_FILE = f\"{EVAL_OUTPUT_DIR}/predictions.json\"\n",
        "ANALYSIS_OUTPUT_DIR = f\"{DRIVE_BASE_DIR}/error_analysis/{TARGET_EXPERIMENT_NAME}\"\n",
        "MODEL_NAME_LABEL = \"T5-Large with Schema Types\"\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(ANALYSIS_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Analyzing predictions from: {PREDICTIONS_FILE}\")\n",
        "print(f\"Saving analysis results to: {ANALYSIS_OUTPUT_DIR}\")\n",
        "print(f\"Using model label: {MODEL_NAME_LABEL}\")\n",
        "\n",
        "if not os.path.exists(PREDICTIONS_FILE):\n",
        "    print(f\"\\n*** WARNING: Predictions file not found at {PREDICTIONS_FILE} ***\")\n",
        "    print(f\"*** Please ensure the path and TARGET_EXPERIMENT_NAME ('{TARGET_EXPERIMENT_NAME}') are correct. ***\")\n",
        "else:\n",
        "    print(\"Predictions file found.\")\n",
        "\n",
        "# --- Utility Functions ---\n",
        "def extract_tables(sql: str) -> List[str]:\n",
        "    from_pattern = r'\\bFROM\\s+([a-zA-Z0-9_]+)'\n",
        "    join_pattern = r'\\bJOIN\\s+([a-zA-Z0-9_]+)'\n",
        "    tables = []\n",
        "    for match in re.finditer(from_pattern, sql, re.IGNORECASE):\n",
        "        tables.append(match.group(1).strip())\n",
        "    for match in re.finditer(join_pattern, sql, re.IGNORECASE):\n",
        "        tables.append(match.group(1).strip())\n",
        "    return tables\n",
        "\n",
        "def extract_columns(sql: str) -> List[str]:\n",
        "    select_pattern = r'\\bSELECT\\s+(.*?)\\s+FROM'\n",
        "    where_pattern = r'\\bWHERE\\s+(.*?)(?:\\bGROUP BY|\\bORDER BY|\\bLIMIT|\\bJOIN|\\bUNION|\\s*$)'\n",
        "    groupby_pattern = r'\\bGROUP BY\\s+(.*?)(?:\\bHAVING|\\bORDER BY|\\bLIMIT|\\s*$)'\n",
        "    orderby_pattern = r'\\bORDER BY\\s+(.*?)(?:\\bLIMIT|\\s*$)'\n",
        "    columns = []\n",
        "    select_match = re.search(select_pattern, sql, re.IGNORECASE | re.DOTALL)\n",
        "    if select_match:\n",
        "        select_cols = select_match.group(1).strip()\n",
        "        select_cols = re.sub(r'[a-zA-Z0-9_]+\\s*\\(([^)]*)\\)', r'\\1', select_cols)\n",
        "        select_cols = re.sub(r'AS\\s+[a-zA-Z0-9_]+', '', select_cols, flags=re.IGNORECASE)\n",
        "        for col in select_cols.split(','):\n",
        "            col = col.strip().split('.')[-1]\n",
        "            if col != '*': columns.append(col)\n",
        "    where_match = re.search(where_pattern, sql, re.IGNORECASE | re.DOTALL)\n",
        "    if where_match:\n",
        "        where_clause = where_match.group(1).strip()\n",
        "        col_matches = re.finditer(r'([a-zA-Z0-9_\\.]+)\\s*(?:=|>|<|>=|<=|!=|LIKE|IN|NOT IN|IS|IS NOT)', where_clause, re.IGNORECASE)\n",
        "        for match in col_matches:\n",
        "            col = match.group(1).strip().split('.')[-1]\n",
        "            columns.append(col)\n",
        "    groupby_match = re.search(groupby_pattern, sql, re.IGNORECASE | re.DOTALL)\n",
        "    if groupby_match:\n",
        "        for col in groupby_match.group(1).strip().split(','):\n",
        "            columns.append(col.strip().split('.')[-1])\n",
        "    orderby_match = re.search(orderby_pattern, sql, re.IGNORECASE | re.DOTALL)\n",
        "    if orderby_match:\n",
        "        orderby_cols = orderby_match.group(1).strip()\n",
        "        orderby_cols = re.sub(r'(?:ASC|DESC)(?:\\s*,|$)', ',', orderby_cols, flags=re.IGNORECASE)\n",
        "        for col in orderby_cols.split(','):\n",
        "            if col.strip(): columns.append(col.strip().split('.')[-1])\n",
        "    return [col for col in columns if col]\n",
        "\n",
        "def has_aggregation(sql: str) -> bool:\n",
        "    \"\"\"Check if SQL query contains aggregation.\"\"\"\n",
        "    agg_pattern = r'\\b(COUNT|SUM|AVG|MIN|MAX|GROUP BY|HAVING)\\b'\n",
        "    return bool(re.search(agg_pattern, sql, re.IGNORECASE))\n",
        "\n",
        "def has_join(sql: str) -> bool:\n",
        "    \"\"\"Check if SQL query contains joins.\"\"\"\n",
        "    join_pattern = r'\\bJOIN\\b'\n",
        "    return bool(re.search(join_pattern, sql, re.IGNORECASE))\n",
        "\n",
        "def has_nesting(sql: str) -> bool:\n",
        "    \"\"\"Check if SQL query contains nested queries.\"\"\"\n",
        "    subquery_pattern = r'\\(\\s*SELECT'\n",
        "    return bool(re.search(subquery_pattern, sql, re.IGNORECASE))\n",
        "\n",
        "def has_order(sql: str) -> bool:\n",
        "    \"\"\"Check if SQL query contains ORDER BY.\"\"\"\n",
        "    order_pattern = r'\\bORDER BY\\b'\n",
        "    return bool(re.search(order_pattern, sql, re.IGNORECASE))\n",
        "\n",
        "def has_limit(sql: str) -> bool:\n",
        "    \"\"\"Check if SQL query contains LIMIT.\"\"\"\n",
        "    limit_pattern = r'\\bLIMIT\\b'\n",
        "    return bool(re.search(limit_pattern, sql, re.IGNORECASE))\n",
        "\n",
        "def has_union(sql: str) -> bool:\n",
        "    \"\"\"Check if SQL query contains UNION.\"\"\"\n",
        "    union_pattern = r'\\bUNION\\b'\n",
        "    return bool(re.search(union_pattern, sql, re.IGNORECASE))\n",
        "\n",
        "def count_conditions(sql: str) -> int:\n",
        "    where_match = re.search(r'\\bWHERE\\s+(.*?)(?:\\bGROUP BY|\\bORDER BY|\\bLIMIT|\\s*$)', sql, re.IGNORECASE | re.DOTALL)\n",
        "    if not where_match: return 0\n",
        "    where_clause = where_match.group(1)\n",
        "    and_count = len(re.findall(r'\\bAND\\b', where_clause, re.IGNORECASE))\n",
        "    or_count = len(re.findall(r'\\bOR\\b', where_clause, re.IGNORECASE))\n",
        "    return 1 + and_count + or_count\n",
        "\n",
        "def categorize_error(gold_sql: str, pred_sql: str) -> Dict[str, bool]:\n",
        "    gold_tables = extract_tables(gold_sql)\n",
        "    pred_tables = extract_tables(pred_sql)\n",
        "    gold_columns = extract_columns(gold_sql)\n",
        "    pred_columns = extract_columns(pred_sql)\n",
        "    error_types = {\n",
        "        'table_selection': not all(table in pred_tables for table in gold_tables),\n",
        "        'column_selection': not all(col in pred_columns for col in gold_columns),\n",
        "        'join_error': has_join(gold_sql) != has_join(pred_sql),\n",
        "        'aggregation_error': has_aggregation(gold_sql) != has_aggregation(pred_sql),\n",
        "        'nesting_error': has_nesting(gold_sql) != has_nesting(pred_sql),\n",
        "        'order_error': has_order(gold_sql) != has_order(pred_sql),\n",
        "        'limit_error': has_limit(gold_sql) != has_limit(pred_sql),\n",
        "        'union_error': has_union(gold_sql) != has_union(pred_sql),\n",
        "        'condition_count_error': count_conditions(gold_sql) != count_conditions(pred_sql),\n",
        "        'syntax_error': 'syntax' in pred_sql.lower() or pred_sql.count('(') != pred_sql.count(')'),\n",
        "        'empty_result': len(pred_sql.strip()) == 0,\n",
        "        'wrong_db_schema': any(table not in gold_tables and table.lower() not in ['t1', 't2', 't3', 't4'] for table in pred_tables if table)\n",
        "    }\n",
        "    return error_types\n",
        "\n",
        "def analyze_predictions(predictions_filepath: str, analysis_output_dir: str, model_label: str):\n",
        "    \"\"\"Analyze predictions and errors.\"\"\"\n",
        "    print(f\"Loading predictions from {predictions_filepath}...\")\n",
        "    try:\n",
        "        with open(predictions_filepath, 'r', encoding='utf-8') as f:\n",
        "             predictions = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: Predictions file not found at {predictions_filepath}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"ERROR: Could not decode JSON from {predictions_filepath}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Analyzing {len(predictions)} predictions\")\n",
        "\n",
        "    error_counts = defaultdict(int)\n",
        "    component_counts = defaultdict(lambda: {'gold': 0, 'pred': 0, 'correct': 0})\n",
        "    db_performance = defaultdict(lambda: {'correct': 0, 'total': 0})\n",
        "    error_examples = defaultdict(list)\n",
        "\n",
        "    for i, item in enumerate(tqdm(predictions, desc=\"Analyzing errors\")):\n",
        "        gold_sql = item.get('gold_sql', '')\n",
        "        pred_sql = item.get('pred_sql', '')\n",
        "        db_id = item.get('db_id', 'unknown_db')\n",
        "        question = item.get('question', '')\n",
        "\n",
        "        is_match = ' '.join(gold_sql.lower().split()) == ' '.join(pred_sql.lower().split())\n",
        "\n",
        "        db_performance[db_id]['total'] += 1\n",
        "        if is_match:\n",
        "            db_performance[db_id]['correct'] += 1\n",
        "\n",
        "        if not is_match:\n",
        "            error_categories = categorize_error(gold_sql, pred_sql)\n",
        "            for error_type, has_error in error_categories.items():\n",
        "                if has_error:\n",
        "                    error_counts[error_type] += 1\n",
        "                    if len(error_examples[error_type]) < 5:\n",
        "                         error_examples[error_type].append({\n",
        "                             'id': i, 'question': question, 'db_id': db_id,\n",
        "                             'gold_sql': gold_sql, 'pred_sql': pred_sql\n",
        "                         })\n",
        "\n",
        "        for component, func in [\n",
        "            ('join', has_join), ('aggregation', has_aggregation), ('nesting', has_nesting),\n",
        "            ('order', has_order), ('limit', has_limit), ('union', has_union)\n",
        "        ]:\n",
        "            has_gold = func(gold_sql)\n",
        "            has_pred = func(pred_sql)\n",
        "            if has_gold: component_counts[component]['gold'] += 1\n",
        "            if has_pred: component_counts[component]['pred'] += 1\n",
        "            if has_gold and has_pred: component_counts[component]['correct'] += 1\n",
        "\n",
        "    # --- Reporting and Plotting ---\n",
        "    total_queries = len(predictions)\n",
        "    if total_queries == 0:\n",
        "        print(\"No predictions found to analyze.\")\n",
        "        return None\n",
        "\n",
        "    error_percentages = {error: count / total_queries * 100 for error, count in error_counts.items()}\n",
        "    sorted_errors = sorted(error_percentages.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Generate report text\n",
        "    report = f\"Error Analysis for {model_label}\\n\"\n",
        "    report += f\"Total queries analyzed: {total_queries}\\n\\n\"\n",
        "    report += \"Error Type Frequencies:\\n\"\n",
        "    for error, percentage in sorted_errors:\n",
        "        report += f\"  {error}: {percentage:.2f}% ({error_counts[error]} instances)\\n\"\n",
        "\n",
        "    report += \"\\nSQL Component Presence Analysis (Recall approximation):\\n\"\n",
        "    component_recall = {}\n",
        "    for component, counts in component_counts.items():\n",
        "         recall = counts['correct'] / counts['gold'] * 100 if counts['gold'] > 0 else 0\n",
        "         component_recall[component] = recall\n",
        "         report += f\"  {component.capitalize()}: {recall:.2f}% ({counts['correct']}/{counts['gold']})\\n\"\n",
        "\n",
        "    report += \"\\nTop 5 Databases by Error Rate (min 5 queries):\\n\"\n",
        "    db_error_rates = {\n",
        "        db_id: 100 * (1 - stats['correct'] / stats['total'])\n",
        "        for db_id, stats in db_performance.items() if stats['total'] >= 5\n",
        "    }\n",
        "    sorted_dbs = sorted(db_error_rates.items(), key=lambda x: x[1], reverse=True)\n",
        "    for db_id, error_rate in sorted_dbs[:5]:\n",
        "        stats = db_performance[db_id]\n",
        "        report += f\"  {db_id}: {error_rate:.2f}% errors ({stats['correct']}/{stats['total']} correct)\\n\"\n",
        "\n",
        "    # Save report text file\n",
        "    report_path = os.path.join(analysis_output_dir, \"error_analysis_report.txt\")\n",
        "    try:\n",
        "        with open(report_path, 'w', encoding='utf-8') as f: f.write(report)\n",
        "        print(f\"Report saved to {report_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving report: {e}\")\n",
        "\n",
        "    # Create error examples file\n",
        "    examples_report = \"Error Examples:\\n\\n\"\n",
        "    for error_type, examples in error_examples.items():\n",
        "        examples_report += f\"== {error_type} Examples ==\\n\"\n",
        "        for i, example in enumerate(examples):\n",
        "            examples_report += f\"Example {i+1}:\\n\"\n",
        "            examples_report += f\"Question: {example.get('question', 'N/A')}\\n\"\n",
        "            examples_report += f\"DB: {example.get('db_id', 'N/A')}\\n\"\n",
        "            examples_report += f\"Gold SQL: {example.get('gold_sql', 'N/A')}\\n\"\n",
        "            examples_report += f\"Pred SQL: {example.get('pred_sql', 'N/A')}\\n\\n\"\n",
        "        examples_report += \"---\\n\\n\"\n",
        "    examples_path = os.path.join(analysis_output_dir, \"error_examples.txt\")\n",
        "    try:\n",
        "        with open(examples_path, 'w', encoding='utf-8') as f: f.write(examples_report)\n",
        "        print(f\"Error examples saved to {examples_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving examples: {e}\")\n",
        "\n",
        "    # --- Plotting ---\n",
        "    sns.set_style(\"whitegrid\")\n",
        "\n",
        "    # 1. Error type distribution\n",
        "    if sorted_errors:\n",
        "        plt.figure(figsize=(12, 7))\n",
        "        error_names = [e.replace('_', ' ').title() for e, _ in sorted_errors]\n",
        "        error_values = [p for _, p in sorted_errors]\n",
        "        ax = sns.barplot(x=error_names, y=error_values, palette=\"muted\")\n",
        "        ax.set_title(f'Error Type Distribution ({model_label})', fontsize=14)\n",
        "        ax.set_xlabel('Error Type', fontsize=12)\n",
        "        ax.set_ylabel('Percentage of Incorrect Queries (%)', fontsize=12)\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "        plot_path = os.path.join(analysis_output_dir, \"error_distribution\")\n",
        "        try:\n",
        "            plt.savefig(f\"{plot_path}.png\", dpi=300)\n",
        "            print(f\"Error distribution chart saved to {plot_path}.png\")\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving error distribution plot: {e}\")\n",
        "\n",
        "\n",
        "    # 2. SQL Component Recall\n",
        "    if component_recall:\n",
        "        components = sorted(component_recall.keys())\n",
        "        recalls = [component_recall[c] for c in components]\n",
        "        component_labels = [c.capitalize() for c in components]\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        ax = sns.barplot(x=component_labels, y=recalls, palette=\"viridis\")\n",
        "        ax.set_title(f'SQL Component Recall ({model_label})', fontsize=14)\n",
        "        ax.set_xlabel('SQL Component', fontsize=12)\n",
        "        ax.set_ylabel('Recall (%)', fontsize=12)\n",
        "        plt.axhline(y=50, color='r', linestyle='--', alpha=0.5)\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.tight_layout()\n",
        "        plot_path = os.path.join(analysis_output_dir, \"component_recall\")\n",
        "        try:\n",
        "            plt.savefig(f\"{plot_path}.png\", dpi=300)\n",
        "            print(f\"Component recall chart saved to {plot_path}.png\")\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving component recall plot: {e}\")\n",
        "\n",
        "    # 3. Database performance (Top 10 worst error rates)\n",
        "    if sorted_dbs:\n",
        "        plt.figure(figsize=(12, 7))\n",
        "        db_names = [db_id for db_id, _ in sorted_dbs[:10]]\n",
        "        error_rates = [rate for _, rate in sorted_dbs[:10]]\n",
        "        ax = sns.barplot(x=db_names, y=error_rates, palette=\"rocket\")\n",
        "        ax.set_title(f'Top 10 Databases by Error Rate ({model_label})', fontsize=14)\n",
        "        ax.set_xlabel('Database ID', fontsize=12)\n",
        "        ax.set_ylabel('Error Rate (%)', fontsize=12)\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.ylim(0, 100)\n",
        "        plt.tight_layout()\n",
        "        plot_path = os.path.join(analysis_output_dir, \"db_error_rates\")\n",
        "        try:\n",
        "            plt.savefig(f\"{plot_path}.png\", dpi=300)\n",
        "            print(f\"DB error rates chart saved to {plot_path}.png\")\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving DB error rate plot: {e}\")\n",
        "\n",
        "    # Return summary statistics dictionary\n",
        "    analysis_results = {\n",
        "        'total_queries': total_queries,\n",
        "        'error_counts': dict(error_counts),\n",
        "        'error_percentages': error_percentages,\n",
        "        'component_recall': component_recall,\n",
        "        'db_error_rates': db_error_rates\n",
        "    }\n",
        "    return analysis_results\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if os.path.exists(PREDICTIONS_FILE):\n",
        "    print(\"\\n--- Running Error Analysis ---\")\n",
        "    analysis_summary = analyze_predictions(\n",
        "        predictions_filepath=PREDICTIONS_FILE,\n",
        "        analysis_output_dir=ANALYSIS_OUTPUT_DIR,\n",
        "        model_label=MODEL_NAME_LABEL\n",
        "    )\n",
        "\n",
        "    if analysis_summary:\n",
        "        print(\"\\n--- Analysis Summary ---\")\n",
        "        print(f\"Total queries analyzed: {analysis_summary['total_queries']}\")\n",
        "        print(\"\\nTop 3 error types:\")\n",
        "        summary_sorted_errors = sorted(analysis_summary['error_percentages'].items(), key=lambda x: x[1], reverse=True)\n",
        "        for error, percentage in summary_sorted_errors[:3]:\n",
        "            print(f\"  {error.replace('_', ' ').title()}: {percentage:.2f}% ({analysis_summary['error_counts'].get(error, 0)})\")\n",
        "\n",
        "        print(\"\\nSQL Component Recall:\")\n",
        "        summary_sorted_components = sorted(analysis_summary['component_recall'].items(), key=lambda x: x[1], reverse=True)\n",
        "        for component, recall in summary_sorted_components:\n",
        "            print(f\"  {component.capitalize()}: {recall:.2f}%\")\n",
        "\n",
        "        print(f\"\\nFull analysis report and charts saved to: {ANALYSIS_OUTPUT_DIR}\")\n",
        "    else:\n",
        "        print(\"\\nAnalysis could not be completed.\")\n",
        "else:\n",
        "    print(f\"\\nSkipping analysis because predictions file was not found: {PREDICTIONS_FILE}\")\n",
        "\n",
        "print(\"\\n--- Error Analysis Script Finished ---\")\n",
        "print(f\"Find results in your Google Drive: {ANALYSIS_OUTPUT_DIR}\")"
      ]
    }
  ]
}